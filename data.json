[
    {
        "title": "The Phantom Plateau",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "1-13",
        "authors": ["Keller, F. S."],
        "url": "https://onlinelibrary.wiley.com/doi/10.1901/jeab.1958.1-1",
        "process": "Taking Dictation",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "None"
    },
    {
        "title": "A Conjunctive Schedule of Reinforcement",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "15-24",
        "authors": ["Herrnstein, R. J.", "Morse, W. H."],
        "url": "https://doi.org/10.1901/jeab.1958.1-15",
        "process": ["Conjunctive Schedules", "Schedule: Fixed Interval", "Schedule: Fixed Ratio", "Reinforcement"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "", 
        "abstract": "Two pigeons were trained on a 15-minute, fixed-interval schedule. They were then trained on the conjunctive fixed-interval, fixed-ratio schedule, in which a response is reinforced only after the passage of a specified time and the emission of a minimal number of unreinforced responses. The period of time was kept at 15 minutes, while the number requirement was varied from 10 to 240 responses. Increasing the number requirement had the effect of decreasing the average rate of responding. The presence of the number requirement also changed the patternof responding within the 15-minute period from that obtained with ordinary fixed-interval reinforcement."
    }, 
    {
        "title": "Operant Extinction After Fixed-Interval Schedules with Young Children",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "25-29",
        "authors": ["Bijou, S. W."],
        "url": "https://doi.org/10.1901/jeab.1958.1-25",
        "process": ["Operant Extinction", "Schedule: Fixed Interval", "Reinforcement"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Four preschool children (~4 years old) were trained on fixed-interval schedules (FI 20 s, FI 30 s, FI 60 s) using plastic trinkets and, at times, dispenser-motor hum as reinforcers. After several conditioning sessions (3–4 per child, spaced ~22–29 days), extinction was introduced following a brief sequence of programmed reinforcers on the trained FI. Extinction performance, plotted cumulatively, showed marked individual variability, with higher extinction response rates generally observed following longer FI schedules (e.g., ~84 responses/min after FI 60 vs. ~10 after FI 20), and no clear relation to baseline (operant-level) rates. Observational notes suggested that self-generated behaviors (e.g., counting, self-talk, toy manipulation) appeared to modulate extinction, potentially functioning as discriminative or competing stimuli. The paper argues that, compared with nonhuman preparations, children introduce uncontrolled, response-produced stimuli that can either sustain or suppress responding during extinction, motivating future studies to bring such variables under experimental control."
    },
    {
        "title": "A Method for Obtaining Psychophysical Thresholds from the Pigeon",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "31-43",
        "authors": ["Blough, D. S."],
        "url": "https://doi.org/10.1901/jeab.1958.1-31",
        "process": ["Psychophysical Threshold", "Stimulus Control", "Shaping", "Variable Ratio", "Variable Interval", "Schedule: Fixed Ratio", "Reinforcement", "Punishment"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "A psychophysical method for measuring the pigeon’s absolute visual threshold, combining Bekesy’s human audiometric tracking technique with operant conditioning procedures is described. Pigeons peck one key (A) when a lighted stimulus patch is visible and another (B) when it appears dark. Pecking key A reduces stimulus intensity; pecking key B increases it. Correct sequences under variable-ratio and variable-interval schedules maintain stimulus control and drive the stimulus intensity to oscillate across the bird’s threshold, yielding a continuous graphical record. Special contingencies—such as penalties for incorrect pecks, enforced pauses when switching keys, occasional omission of light after reinforcement, and differentiated reinforcement for below-threshold vs. above-threshold conditions—enhance control and minimize artifacts like wandering thresholds. The procedure can be generalized to measure other sensory thresholds by substituting appropriate stimulus continua. Its applicability to both absolute and differential thresholds are discussed."
    },
    {
        "title": "The Behavioral Effects of Some Temporally Defined Schedules of Reinforcement",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "45-55",
        "authors": ["Hearst, E."],
        "url": "https://doi.org/10.1901/jeab.1958.1-45",
        "process": ["Schedule: Fixed Interval", "Limited Hold", "Ratio-like Performance"],
        "static-equation": "",
        "static-equation-definitions": "", 
        "recursive-equation": "",
        "recursive-equation-definitions": "", 
        "abstract": "Pigeons were trained under reinforcement schedules defined by alternating periods during which a single response could be reinforced ($t_D$) with periods in which no reinforcement was available ($t_A$). The ratio $T = t_D/(t_D + t_A)$ was varied systematically while the total cycle length remained constant at 30 seconds. Four subjects were studied as $T$ was reduced from 1.00 (equivalent to a fixed-interval 30-second schedule) to values as low as 0.013. Decreases in $T$ produced marked increases in overall response rates and responses per reinforcement, and cumulative records shifted from patterns resembling fixed-interval performance to those characteristic of fixed-ratio or variable-ratio schedules. At the smallest values of $T$, some birds showed irregularities and pauses comparable to \\\"ratio strain.\\\" Interresponse-time distributions revealed a progressive increase in the relative frequency of short IRTs with decreasing $T$. The results demonstrate that interval-like and ratio-like performances can be obtained within a single framework of temporally defined variables, and that systematic changes in limited-hold duration generate a transition from interval to ratio behavior."
      },
    {
        "title": "The effects of deprivation upon temporally spaced responding",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "59-65",
        "authors": ["Conrad, D. G.", "Sidman, M.", "Herrnstein, R. J."],
        "url": "https://doi.org/10.1901/jeab.1958.1-59",
        "process": ["Timing", "DRL", "Stimulus Generalization"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Five rats and a rhesus monkey were trained to space their responses at least 20 seconds apart. The performances of the monkey and one rat were tested after five periods of deprivation ranging from zero to 72 hours and 9 to 69. 5 hours, re-spectively. Two rats received a 10-hour test session during which the accumu-lation of reinforcements produced satiation. Two other rats were trained to spacetheir responses by at least 20 seconds but not more than 24 seconds. The last twoanimals were also tested in a 10-hour satiation session.In all cases the major effect upon performance of manipulating deprivation inthe DRL situation was observed to occur only after short deprivations or when theanimals were near satiation. With greater satiation, long IRT' s became more fre-quent and response rates dropped. Over a wide range of deprivations, little changein the performance could be detected."
    }, 
    {
        "title": "Diagramming Schedules of Reinforcement",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "67-68",
        "authors": ["Skinner, B. F."],
        "url": "https://doi.org/10.1901/jeab.1958.1-67",
        "process": ["Schedules of Reinforcement", "Schedule: Fixed Interval", "Schedule: Fixed Ratio", "Schedule: Variable Ratio", "Schedule: Variable Interval", "Schedule: Interlocking", "Schedule: Tandem", "Schedule: Chained", "Schedule: Mixed", "Schedule: Multiple", "Reinforcement"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "A graphical method for representing schedules of reinforcement is described. Cumulative records of responding are used as coordinates, with reinforcement specified by lines relating responses to time. The system depicts ratio and interval schedules, as well as their variable, alternative, conjunctive, interlocking, tandem, chained, mixed, and multiple forms. The method provides a compact notation for analyzing contingencies of reinforcement and suggests possible extensions to aversive control and punishment."
    }, 
    {
        "title": "Avoidance Behavior and the Development of Gastroduodenal Ulcers",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "69-72",
        "authors": ["Brady, J. V.", "Porter, R. W.", "Conrad, D. G.", "Mason, J. W."],
        "url": "https://doi.org/10.1901/jeab.1958.1-69",
        "process": ["Avoidance"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Eight rhesus monkeys were studied in a yoked-chair avoidance procedure in which one animal could postpone footshock for both members of the pair by lever pressing. Experimental animals developed stable avoidance responding, while yoked controls received identical shock exposure without control over its occurrence. Over weeks of continuous testing, all avoidance animals developed severe gastroduodenal ulceration, while controls did not. Measures of corticosteroid excretion showed no consistent elevations. The findings suggest that the behavioral contingencies of avoidance, rather than physical shock exposure alone, may be critical in the etiology of gastrointestinal pathology under conditions of prolonged stress."
    }, 
    {
        "title": "Effects of Chlorpromazine and Promazine on Performance on a Mixed Schedule of Reinforcement",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "73-82",
        "authors": ["Dews, P. B."],
        "url": "https://doi.org/10.1901/jeab.1958.1-73",
        "process": ["Schedule: Mixed", "Schedule: Fixed Interval", "Schedule: Fixed Ratio", "Behavioral Pharmacology"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Drugs are known to alter operant behavior, yet their influence on discriminations without explicit external cues was less defined. This study examined the effects of chlorpromazine and promazine on pigeons responding under a mixed FI 15/FR 50 schedule. Four birds were maintained at 80% body weight and tested across repeated daily sessions, with drug or control injections administered prior to performance. Under control conditions, stable responding developed, including second-order effects where FI pauses varied depending on preceding schedule components. Both drugs reduced the characteristic postreinforcement pauses in fixed-interval components, with promazine at higher doses producing striking increases in overall response output compared to chlorpromazine. Importantly, drug effects selectively disrupted subtle schedule-controlled discriminations while leaving gross discriminations and ratio performance largely intact. These findings underscore the utility of complex schedules as analytic tools for detecting differential drug effects on behavioral organization."
    },
    {
        "title": "The Grooming Behavior of the Chimpanzee as a Reinforcer",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "83-85",
        "authors": ["Falk, J. L."],
        "url": "https://doi.org/10.1901/jeab.1958.1-83",
        "process": ["Discrimination Learning", "Reinforcement"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Grooming is a pervasive primate social behavior, yet its potential function as a reinforcer had not been directly tested. A young chimpanzee was provided access to grooming the experimenter’s arm contingent upon correct visual discrimination responses. Thirty-second periods of grooming, signaled by a clicker, reliably maintained responding, and the animal acquired both the original discrimination (square vs. cross) and a subsequent reversal. Despite its immature age, the subject showed strong motivation for grooming, likely amplified by extended social isolation. The study demonstrates that grooming, beyond its social and hygienic functions, can serve as an effective reinforcer for operant behavior. These findings extend the range of known reinforcers and suggest that species-typical social activities may be integrated into experimental analyses of behavior."
    },
    {
        "title": "Stimulus-Producing Responses in Chimpanzees",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "87-102",
        "authors": ["Kelleher, R. T."],
        "url": "https://doi.org/10.1901/jeab.1958.1-87",
        "process": ["Discrimination Learning", "Schedule: Fixed Interval", "Schedule: Variable Ratio", "Reinforcement", "Observing Responses"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Discrimination learning often requires not only food-producing responses (Rf) but also stimulus-producing responses (Rs) that bring discriminative cues under experimental control. Previous analyses inferred Rs indirectly, but this study directly examined them in chimpanzees. Using a two-key procedure, one key delivered food under fixed-interval or variable-ratio schedules (Rf), while the other produced red or blue lights correlated with reinforcement or extinction (Rs). Across multiple experiments, chimpanzees maintained substantial Rs rates, especially under fixed-ratio reinforcement of stimuli, and discriminations were strong (DRs near 1.0). Extinction or nondifferential stimuli rapidly abolished Rs performance, confirming that discriminative function—not mere stimulus onset—maintains responding. The work establishes Rs as operant behaviors governed by reinforcement schedules and provides an objective method for studying “observing responses.” These findings highlight Rs as essential behavioral processes for analyzing discrimination, attention, and conditioned reinforcement."
    },
    {
        "title": "Some Factors Involved in the Stimulus Control of Operant Behavior",
        "year": 1958,
        "volume": 1,
        "issue": 1,
        "pages": "103-107",
        "authors": ["Morse, W. H.", "Skinner, B. F."],
        "url": "https://doi.org/10.1901/jeab.1958.1-103",
        "process": ["Stimulus Control", "Schedule: Variable Interval", "Extinction", "Reinforcement"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "Stimulus control in operant behavior arises when reinforcement delivered in the presence of a discriminative stimulus (SD) alters the subsequent probability of responding. Earlier research had shown that temporal pairing of SD and reinforcement could produce generalization gradients, but the role of the operant response itself remained uncertain. This study tested whether stimulus–reinforcer pairing, independent of the response, was sufficient to establish stimulus control. Pigeons first received food on a variable-interval schedule in the presence of one color light but never in another. Later, key pecking was conditioned in white light, then extinguished while the colored lights alternated. Birds responded preferentially in the stimulus previously correlated with food, though less strongly than if responses had been differentially reinforced. These results confirm that temporal pairing of stimulus and reinforcement alone contributes to stimulus control, though direct response–stimulus contingencies sharpen the effect. The findings clarify boundary conditions for how discriminative stimuli acquire control of operant behavior."
    },
    {
        "title": "Probability Relations within Response Sequences Under Ratio Reinforcement",
        "year": 1958,
        "volume": 1,
        "issue": 2,
        "pages": "109-121",
        "authors": ["Mechner, F."],
        "url": "https://doi.org/10.1901/jeab.1958.1-109",
        "process": ["Schedule: Fixed Ratio", "Reinforcement", "Discrimination Learning", "Response Produced Stimuli"],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": "A procedure was developed for the purpose of investigating the internal cohesion of response sequences maintained on fixed-ratio reinforcement. Under this procedure, rats were trained in a two-lever Skinner box on a schedule wherein water reinforcement was delivered either upon the completion of N consecutive responses on lever A, or else upon the completion of a minimum of N consecutive responses on lever A followed by an additional response on lever B. A random programmer determined which of these two conditions prevailed on any run. The two main parameters investigated were N (the minimum number of responses required for reinforcement) and P (the probability that the animal is reinforced immediately upon the completion of the N responses on lever A). The values of N used were 4, 8, 12, and 16, and the values of P were 0.00, 0.25, 0.50, and 0.75. The following two functions were calculated for the data of each animal for each of the four values of the variable to which it was exposed: (a) the probability of switching to lever B as a function of the number of responses already made on lever A, and (b) the frequency distributions of lengths of runs. The effect of increasing N was a shift in both of these functions upward along the abscissa, in such a way that the sharpest rise in function (a) and the median of distribution (b) always fell slightly above the stipulated value of N. The effect of increasing P was qualitatively similar to the effect of increasing N."
    },
    {
        "title": "",
        "year": 1958,
        "volume": 1,
        "issue": 2,
        "pages": "",
        "authors": [],
        "url": "",
        "process": [],
        "static-equation": "",
        "static-equation-definitions": "",
        "recursive-equation": "",
        "recursive-equation-definitions": "",
        "abstract": ""
    }
]